{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "<br>\n",
        "<font>\n",
        "<!-- <img src=\"https://cdn.freebiesupply.com/logos/large/2x/sharif-logo-png-transparent.png\" alt=\"SUT logo\" width=300 height=300 align=left class=\"saturate\"> -->\n",
        "<div dir=ltr align=center>\n",
        "<img src=\"https://cdn.freebiesupply.com/logos/large/2x/sharif-logo-png-transparent.png\" width=200 height=200>\n",
        "<br>\n",
        "<font color=0F5298 size=7>\n",
        "Deep Learning <br>\n",
        "<font color=2565AE size=5>\n",
        "Electrical Engineering Department <br>\n",
        "Fall 2024<br>\n",
        "<font color=3C99D size=5>\n",
        "Project <br>\n",
        "<font color=696880 size=4>\n",
        "<!-- <br> -->\n",
        "\n",
        "\n",
        "____"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<font color=2565AE size=6>\n",
        "Parsa Hatami <br>\n",
        "<font color=2565AE size=6>\n",
        "400100962 <br>\n",
        "\n",
        "____"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Uploading the best model that we have saved from the Detection part."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "OKnqcrpTp2dd",
        "outputId": "13a94b0f-63ec-4ae4-c55b-ee1db7006c40"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d33932f5-9d42-4961-8f65-f9831ff662b3\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-d33932f5-9d42-4961-8f65-f9831ff662b3\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving best.pt to best.pt\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()  # Manually upload your file\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-aRxAzyqWRR",
        "outputId": "5dddf7aa-b788-4ec3-850b-80b10ad9c71a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['.config', 'best.pt', 'drive', 'sample_data']"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# List files in the current directory\n",
        "os.listdir()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "pinAYucoq5jb",
        "outputId": "42c4ad96-8851-4fe8-9fe2-ef2db8650c22"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/models/best.pt'"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import shutil\n",
        "\n",
        "# Create a directory and move the file\n",
        "os.makedirs(\"/content/models\", exist_ok=True)\n",
        "shutil.move(\"best.pt\", \"/content/models/best.pt\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "VumRIb6jr-Sd"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import kagglehub\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "import cv2\n",
        "import os\n",
        "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
        "from ultralytics import YOLO\n",
        "from typing import Dict, List, Tuple"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uo1KuJqssAnS",
        "outputId": "6eb69bfe-c4c0-4f03-98c7-b28fc5cb42ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.11/dist-packages (1.6.17)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.11/dist-packages (from kaggle) (1.17.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2024.12.14)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from kaggle) (4.67.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.11/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.3.0)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from kaggle) (6.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.11/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kaggle) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->kaggle) (3.10)\n"
          ]
        }
      ],
      "source": [
        "!pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gg3PpQm7sFbe",
        "outputId": "d15d45fb-cc86-44b9-d861-abe5cc8b4480"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/ayushspai/sportsmot?dataset_version_number=1...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 33.5G/33.5G [07:35<00:00, 79.0MB/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/ayushspai/sportsmot/versions/1\n",
            "cp: cannot create directory '/content/drive/MyDrive/Project/': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "  # Download dataset using kagglehub\n",
        "  path = kagglehub.dataset_download(\"ayushspai/sportsmot\")\n",
        "  print(\"Path to dataset files:\", path)\n",
        "\n",
        "  !cp -r /root/.cache/kagglehub/datasets/ayushspai/sportsmot/versions/1/sportsmot_publish/splits_txt /content/drive/MyDrive/Project/\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### See the folders inside each sequence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DzMy_8CNshXN",
        "outputId": "fc1b988c-8bba-4e82-c10a-ec3501dd1609"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "gt  img1  seqinfo.ini\n"
          ]
        }
      ],
      "source": [
        "!ls /root/.cache/kagglehub/datasets/ayushspai/sportsmot/versions/1/sportsmot_publish/dataset/train/v_1LwtoLPw2TU_c006"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Creating video from sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-tqVCa4Nsph6",
        "outputId": "a4c1836d-6120-4ad4-f1dc-68731dd78f26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Video created successfully! Saved at: /content/v_G-vNjfx1GGc_c600_video.mp4\n"
          ]
        }
      ],
      "source": [
        "sequence_path = \"/root/.cache/kagglehub/datasets/ayushspai/sportsmot/versions/1/sportsmot_publish/dataset/val/v_G-vNjfx1GGc_c600/img1\"\n",
        "output_video_path = \"/content/v_G-vNjfx1GGc_c600_video.mp4\"\n",
        "\n",
        "frame_files = sorted(os.listdir(sequence_path))\n",
        "\n",
        "first_frame_path = os.path.join(sequence_path, frame_files[0])\n",
        "first_frame = cv2.imread(first_frame_path)\n",
        "\n",
        "height, width, _ = first_frame.shape\n",
        "\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "fps = 25.0\n",
        "out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
        "\n",
        "for frame_file in frame_files:\n",
        "    frame_path = os.path.join(sequence_path, frame_file)\n",
        "    frame = cv2.imread(frame_path)\n",
        "\n",
        "    if frame is not None:\n",
        "        out.write(frame)\n",
        "\n",
        "out.release()\n",
        "\n",
        "print(f\"✅ Video created successfully! Saved at: {output_video_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "Tgp0waZJsugV",
        "outputId": "c232bf36-fe99-4510-cc5c-912ca29e8de6"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_e6a3bea8-0546-4745-931d-db8469d05cf5\", \"v_G-vNjfx1GGc_c600_video.mp4\", 19579896)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.download(output_video_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rP2lwXe1kFII",
        "outputId": "8470cbc9-e39c-430b-d133-97129ae662f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting deep_sort_realtime\n",
            "  Downloading deep_sort_realtime-1.3.2-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from deep_sort_realtime) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from deep_sort_realtime) (1.13.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from deep_sort_realtime) (4.10.0.84)\n",
            "Downloading deep_sort_realtime-1.3.2-py3-none-any.whl (8.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m42.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: deep_sort_realtime\n",
            "Successfully installed deep_sort_realtime-1.3.2\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m914.9/914.9 kB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m123.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m95.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m61.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m100.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.5/161.5 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install deep_sort_realtime\n",
        "!pip install ultralytics --quiet\n",
        "!pip install motmetrics --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CFJ4zilfmkRp",
        "outputId": "eb9de952-1a67-4879-b617-b10ebe7a10db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total frames: 500\n",
            "Frame size: 1280x720\n",
            "FPS: 25.0\n",
            "Frame 1/500 processed.\n",
            "Frame 2/500 processed.\n",
            "Frame 3/500 processed.\n",
            "Frame 4/500 processed.\n",
            "Frame 5/500 processed.\n",
            "Frame 6/500 processed.\n",
            "Frame 7/500 processed.\n",
            "Frame 8/500 processed.\n",
            "Frame 9/500 processed.\n",
            "Frame 10/500 processed.\n",
            "Frame 11/500 processed.\n",
            "Frame 12/500 processed.\n",
            "Frame 13/500 processed.\n",
            "Frame 14/500 processed.\n",
            "Frame 15/500 processed.\n",
            "Frame 16/500 processed.\n",
            "Frame 17/500 processed.\n",
            "Frame 18/500 processed.\n",
            "Frame 19/500 processed.\n",
            "Frame 20/500 processed.\n",
            "Frame 21/500 processed.\n",
            "Frame 22/500 processed.\n",
            "Frame 23/500 processed.\n",
            "Frame 24/500 processed.\n",
            "Frame 25/500 processed.\n",
            "Frame 26/500 processed.\n",
            "Frame 27/500 processed.\n",
            "Frame 28/500 processed.\n",
            "Frame 29/500 processed.\n",
            "Frame 30/500 processed.\n",
            "Frame 31/500 processed.\n",
            "Frame 32/500 processed.\n",
            "Frame 33/500 processed.\n",
            "Frame 34/500 processed.\n",
            "Frame 35/500 processed.\n",
            "Frame 36/500 processed.\n",
            "Frame 37/500 processed.\n",
            "Frame 38/500 processed.\n",
            "Frame 39/500 processed.\n",
            "Frame 40/500 processed.\n",
            "Frame 41/500 processed.\n",
            "Frame 42/500 processed.\n",
            "Frame 43/500 processed.\n",
            "Frame 44/500 processed.\n",
            "Frame 45/500 processed.\n",
            "Frame 46/500 processed.\n",
            "Frame 47/500 processed.\n",
            "Frame 48/500 processed.\n",
            "Frame 49/500 processed.\n",
            "Frame 50/500 processed.\n",
            "Frame 51/500 processed.\n",
            "Frame 52/500 processed.\n",
            "Frame 53/500 processed.\n",
            "Frame 54/500 processed.\n",
            "Frame 55/500 processed.\n",
            "Frame 56/500 processed.\n",
            "Frame 57/500 processed.\n",
            "Frame 58/500 processed.\n",
            "Frame 59/500 processed.\n",
            "Frame 60/500 processed.\n",
            "Frame 61/500 processed.\n",
            "Frame 62/500 processed.\n",
            "Frame 63/500 processed.\n",
            "Frame 64/500 processed.\n",
            "Frame 65/500 processed.\n",
            "Frame 66/500 processed.\n",
            "Frame 67/500 processed.\n",
            "Frame 68/500 processed.\n",
            "Frame 69/500 processed.\n",
            "Frame 70/500 processed.\n",
            "Frame 71/500 processed.\n",
            "Frame 72/500 processed.\n",
            "Frame 73/500 processed.\n",
            "Frame 74/500 processed.\n",
            "Frame 75/500 processed.\n",
            "Frame 76/500 processed.\n",
            "Frame 77/500 processed.\n",
            "Frame 78/500 processed.\n",
            "Frame 79/500 processed.\n",
            "Frame 80/500 processed.\n",
            "Frame 81/500 processed.\n",
            "Frame 82/500 processed.\n",
            "Frame 83/500 processed.\n",
            "Frame 84/500 processed.\n",
            "Frame 85/500 processed.\n",
            "Frame 86/500 processed.\n",
            "Frame 87/500 processed.\n",
            "Frame 88/500 processed.\n",
            "Frame 89/500 processed.\n",
            "Frame 90/500 processed.\n",
            "Frame 91/500 processed.\n",
            "Frame 92/500 processed.\n",
            "Frame 93/500 processed.\n",
            "Frame 94/500 processed.\n",
            "Frame 95/500 processed.\n",
            "Frame 96/500 processed.\n",
            "Frame 97/500 processed.\n",
            "Frame 98/500 processed.\n",
            "Frame 99/500 processed.\n",
            "Frame 100/500 processed.\n",
            "Frame 101/500 processed.\n",
            "Frame 102/500 processed.\n",
            "Frame 103/500 processed.\n",
            "Frame 104/500 processed.\n",
            "Frame 105/500 processed.\n",
            "Frame 106/500 processed.\n",
            "Frame 107/500 processed.\n",
            "Frame 108/500 processed.\n",
            "Frame 109/500 processed.\n",
            "Frame 110/500 processed.\n",
            "Frame 111/500 processed.\n",
            "Frame 112/500 processed.\n",
            "Frame 113/500 processed.\n",
            "Frame 114/500 processed.\n",
            "Frame 115/500 processed.\n",
            "Frame 116/500 processed.\n",
            "Frame 117/500 processed.\n",
            "Frame 118/500 processed.\n",
            "Frame 119/500 processed.\n",
            "Frame 120/500 processed.\n",
            "Frame 121/500 processed.\n",
            "Frame 122/500 processed.\n",
            "Frame 123/500 processed.\n",
            "Frame 124/500 processed.\n",
            "Frame 125/500 processed.\n",
            "Frame 126/500 processed.\n",
            "Frame 127/500 processed.\n",
            "Frame 128/500 processed.\n",
            "Frame 129/500 processed.\n",
            "Frame 130/500 processed.\n",
            "Frame 131/500 processed.\n",
            "Frame 132/500 processed.\n",
            "Frame 133/500 processed.\n",
            "Frame 134/500 processed.\n",
            "Frame 135/500 processed.\n",
            "Frame 136/500 processed.\n",
            "Frame 137/500 processed.\n",
            "Frame 138/500 processed.\n",
            "Frame 139/500 processed.\n",
            "Frame 140/500 processed.\n",
            "Frame 141/500 processed.\n",
            "Frame 142/500 processed.\n",
            "Frame 143/500 processed.\n",
            "Frame 144/500 processed.\n",
            "Frame 145/500 processed.\n",
            "Frame 146/500 processed.\n",
            "Frame 147/500 processed.\n",
            "Frame 148/500 processed.\n",
            "Frame 149/500 processed.\n",
            "Frame 150/500 processed.\n",
            "Frame 151/500 processed.\n",
            "Frame 152/500 processed.\n",
            "Frame 153/500 processed.\n",
            "Frame 154/500 processed.\n",
            "Frame 155/500 processed.\n",
            "Frame 156/500 processed.\n",
            "Frame 157/500 processed.\n",
            "Frame 158/500 processed.\n",
            "Frame 159/500 processed.\n",
            "Frame 160/500 processed.\n",
            "Frame 161/500 processed.\n",
            "Frame 162/500 processed.\n",
            "Frame 163/500 processed.\n",
            "Frame 164/500 processed.\n",
            "Frame 165/500 processed.\n",
            "Frame 166/500 processed.\n",
            "Frame 167/500 processed.\n",
            "Frame 168/500 processed.\n",
            "Frame 169/500 processed.\n",
            "Frame 170/500 processed.\n",
            "Frame 171/500 processed.\n",
            "Frame 172/500 processed.\n",
            "Frame 173/500 processed.\n",
            "Frame 174/500 processed.\n",
            "Frame 175/500 processed.\n",
            "Frame 176/500 processed.\n",
            "Frame 177/500 processed.\n",
            "Frame 178/500 processed.\n",
            "Frame 179/500 processed.\n",
            "Frame 180/500 processed.\n",
            "Frame 181/500 processed.\n",
            "Frame 182/500 processed.\n",
            "Frame 183/500 processed.\n",
            "Frame 184/500 processed.\n",
            "Frame 185/500 processed.\n",
            "Frame 186/500 processed.\n",
            "Frame 187/500 processed.\n",
            "Frame 188/500 processed.\n",
            "Frame 189/500 processed.\n",
            "Frame 190/500 processed.\n",
            "Frame 191/500 processed.\n",
            "Frame 192/500 processed.\n",
            "Frame 193/500 processed.\n",
            "Frame 194/500 processed.\n",
            "Frame 195/500 processed.\n",
            "Frame 196/500 processed.\n",
            "Frame 197/500 processed.\n",
            "Frame 198/500 processed.\n",
            "Frame 199/500 processed.\n",
            "Frame 200/500 processed.\n",
            "Frame 201/500 processed.\n",
            "Frame 202/500 processed.\n",
            "Frame 203/500 processed.\n",
            "Frame 204/500 processed.\n",
            "Frame 205/500 processed.\n",
            "Frame 206/500 processed.\n",
            "Frame 207/500 processed.\n",
            "Frame 208/500 processed.\n",
            "Frame 209/500 processed.\n",
            "Frame 210/500 processed.\n",
            "Frame 211/500 processed.\n",
            "Frame 212/500 processed.\n",
            "Frame 213/500 processed.\n",
            "Frame 214/500 processed.\n",
            "Frame 215/500 processed.\n",
            "Frame 216/500 processed.\n",
            "Frame 217/500 processed.\n",
            "Frame 218/500 processed.\n",
            "Frame 219/500 processed.\n",
            "Frame 220/500 processed.\n",
            "Frame 221/500 processed.\n",
            "Frame 222/500 processed.\n",
            "Frame 223/500 processed.\n",
            "Frame 224/500 processed.\n",
            "Frame 225/500 processed.\n",
            "Frame 226/500 processed.\n",
            "Frame 227/500 processed.\n",
            "Frame 228/500 processed.\n",
            "Frame 229/500 processed.\n",
            "Frame 230/500 processed.\n",
            "Frame 231/500 processed.\n",
            "Frame 232/500 processed.\n",
            "Frame 233/500 processed.\n",
            "Frame 234/500 processed.\n",
            "Frame 235/500 processed.\n",
            "Frame 236/500 processed.\n",
            "Frame 237/500 processed.\n",
            "Frame 238/500 processed.\n",
            "Frame 239/500 processed.\n",
            "Frame 240/500 processed.\n",
            "Frame 241/500 processed.\n",
            "Frame 242/500 processed.\n",
            "Frame 243/500 processed.\n",
            "Frame 244/500 processed.\n",
            "Frame 245/500 processed.\n",
            "Frame 246/500 processed.\n",
            "Frame 247/500 processed.\n",
            "Frame 248/500 processed.\n",
            "Frame 249/500 processed.\n",
            "Frame 250/500 processed.\n",
            "Frame 251/500 processed.\n",
            "Frame 252/500 processed.\n",
            "Frame 253/500 processed.\n",
            "Frame 254/500 processed.\n",
            "Frame 255/500 processed.\n",
            "Frame 256/500 processed.\n",
            "Frame 257/500 processed.\n",
            "Frame 258/500 processed.\n",
            "Frame 259/500 processed.\n",
            "Frame 260/500 processed.\n",
            "Frame 261/500 processed.\n",
            "Frame 262/500 processed.\n",
            "Frame 263/500 processed.\n",
            "Frame 264/500 processed.\n",
            "Frame 265/500 processed.\n",
            "Frame 266/500 processed.\n",
            "Frame 267/500 processed.\n",
            "Frame 268/500 processed.\n",
            "Frame 269/500 processed.\n",
            "Frame 270/500 processed.\n",
            "Frame 271/500 processed.\n",
            "Frame 272/500 processed.\n",
            "Frame 273/500 processed.\n",
            "Frame 274/500 processed.\n",
            "Frame 275/500 processed.\n",
            "Frame 276/500 processed.\n",
            "Frame 277/500 processed.\n",
            "Frame 278/500 processed.\n",
            "Frame 279/500 processed.\n",
            "Frame 280/500 processed.\n",
            "Frame 281/500 processed.\n",
            "Frame 282/500 processed.\n",
            "Frame 283/500 processed.\n",
            "Frame 284/500 processed.\n",
            "Frame 285/500 processed.\n",
            "Frame 286/500 processed.\n",
            "Frame 287/500 processed.\n",
            "Frame 288/500 processed.\n",
            "Frame 289/500 processed.\n",
            "Frame 290/500 processed.\n",
            "Frame 291/500 processed.\n",
            "Frame 292/500 processed.\n",
            "Frame 293/500 processed.\n",
            "Frame 294/500 processed.\n",
            "Frame 295/500 processed.\n",
            "Frame 296/500 processed.\n",
            "Frame 297/500 processed.\n",
            "Frame 298/500 processed.\n",
            "Frame 299/500 processed.\n",
            "Frame 300/500 processed.\n",
            "Frame 301/500 processed.\n",
            "Frame 302/500 processed.\n",
            "Frame 303/500 processed.\n",
            "Frame 304/500 processed.\n",
            "Frame 305/500 processed.\n",
            "Frame 306/500 processed.\n",
            "Frame 307/500 processed.\n",
            "Frame 308/500 processed.\n",
            "Frame 309/500 processed.\n",
            "Frame 310/500 processed.\n",
            "Frame 311/500 processed.\n",
            "Frame 312/500 processed.\n",
            "Frame 313/500 processed.\n",
            "Frame 314/500 processed.\n",
            "Frame 315/500 processed.\n",
            "Frame 316/500 processed.\n",
            "Frame 317/500 processed.\n",
            "Frame 318/500 processed.\n",
            "Frame 319/500 processed.\n",
            "Frame 320/500 processed.\n",
            "Frame 321/500 processed.\n",
            "Frame 322/500 processed.\n",
            "Frame 323/500 processed.\n",
            "Frame 324/500 processed.\n",
            "Frame 325/500 processed.\n",
            "Frame 326/500 processed.\n",
            "Frame 327/500 processed.\n",
            "Frame 328/500 processed.\n",
            "Frame 329/500 processed.\n",
            "Frame 330/500 processed.\n",
            "Frame 331/500 processed.\n",
            "Frame 332/500 processed.\n",
            "Frame 333/500 processed.\n",
            "Frame 334/500 processed.\n",
            "Frame 335/500 processed.\n",
            "Frame 336/500 processed.\n",
            "Frame 337/500 processed.\n",
            "Frame 338/500 processed.\n",
            "Frame 339/500 processed.\n",
            "Frame 340/500 processed.\n",
            "Frame 341/500 processed.\n",
            "Frame 342/500 processed.\n",
            "Frame 343/500 processed.\n",
            "Frame 344/500 processed.\n",
            "Frame 345/500 processed.\n",
            "Frame 346/500 processed.\n",
            "Frame 347/500 processed.\n",
            "Frame 348/500 processed.\n",
            "Frame 349/500 processed.\n",
            "Frame 350/500 processed.\n",
            "Frame 351/500 processed.\n",
            "Frame 352/500 processed.\n",
            "Frame 353/500 processed.\n",
            "Frame 354/500 processed.\n",
            "Frame 355/500 processed.\n",
            "Frame 356/500 processed.\n",
            "Frame 357/500 processed.\n",
            "Frame 358/500 processed.\n",
            "Frame 359/500 processed.\n",
            "Frame 360/500 processed.\n",
            "Frame 361/500 processed.\n",
            "Frame 362/500 processed.\n",
            "Frame 363/500 processed.\n",
            "Frame 364/500 processed.\n",
            "Frame 365/500 processed.\n",
            "Frame 366/500 processed.\n",
            "Frame 367/500 processed.\n",
            "Frame 368/500 processed.\n",
            "Frame 369/500 processed.\n",
            "Frame 370/500 processed.\n",
            "Frame 371/500 processed.\n",
            "Frame 372/500 processed.\n",
            "Frame 373/500 processed.\n",
            "Frame 374/500 processed.\n",
            "Frame 375/500 processed.\n",
            "Frame 376/500 processed.\n",
            "Frame 377/500 processed.\n",
            "Frame 378/500 processed.\n",
            "Frame 379/500 processed.\n",
            "Frame 380/500 processed.\n",
            "Frame 381/500 processed.\n",
            "Frame 382/500 processed.\n",
            "Frame 383/500 processed.\n",
            "Frame 384/500 processed.\n",
            "Frame 385/500 processed.\n",
            "Frame 386/500 processed.\n",
            "Frame 387/500 processed.\n",
            "Frame 388/500 processed.\n",
            "Frame 389/500 processed.\n",
            "Frame 390/500 processed.\n",
            "Frame 391/500 processed.\n",
            "Frame 392/500 processed.\n",
            "Frame 393/500 processed.\n",
            "Frame 394/500 processed.\n",
            "Frame 395/500 processed.\n",
            "Frame 396/500 processed.\n",
            "Frame 397/500 processed.\n",
            "Frame 398/500 processed.\n",
            "Frame 399/500 processed.\n",
            "Frame 400/500 processed.\n",
            "Frame 401/500 processed.\n",
            "Frame 402/500 processed.\n",
            "Frame 403/500 processed.\n",
            "Frame 404/500 processed.\n",
            "Frame 405/500 processed.\n",
            "Frame 406/500 processed.\n",
            "Frame 407/500 processed.\n",
            "Frame 408/500 processed.\n",
            "Frame 409/500 processed.\n",
            "Frame 410/500 processed.\n",
            "Frame 411/500 processed.\n",
            "Frame 412/500 processed.\n",
            "Frame 413/500 processed.\n",
            "Frame 414/500 processed.\n",
            "Frame 415/500 processed.\n",
            "Frame 416/500 processed.\n",
            "Frame 417/500 processed.\n",
            "Frame 418/500 processed.\n",
            "Frame 419/500 processed.\n",
            "Frame 420/500 processed.\n",
            "Frame 421/500 processed.\n",
            "Frame 422/500 processed.\n",
            "Frame 423/500 processed.\n",
            "Frame 424/500 processed.\n",
            "Frame 425/500 processed.\n",
            "Frame 426/500 processed.\n",
            "Frame 427/500 processed.\n",
            "Frame 428/500 processed.\n",
            "Frame 429/500 processed.\n",
            "Frame 430/500 processed.\n",
            "Frame 431/500 processed.\n",
            "Frame 432/500 processed.\n",
            "Frame 433/500 processed.\n",
            "Frame 434/500 processed.\n",
            "Frame 435/500 processed.\n",
            "Frame 436/500 processed.\n",
            "Frame 437/500 processed.\n",
            "Frame 438/500 processed.\n",
            "Frame 439/500 processed.\n",
            "Frame 440/500 processed.\n",
            "Frame 441/500 processed.\n",
            "Frame 442/500 processed.\n",
            "Frame 443/500 processed.\n",
            "Frame 444/500 processed.\n",
            "Frame 445/500 processed.\n",
            "Frame 446/500 processed.\n",
            "Frame 447/500 processed.\n",
            "Frame 448/500 processed.\n",
            "Frame 449/500 processed.\n",
            "Frame 450/500 processed.\n",
            "Frame 451/500 processed.\n",
            "Frame 452/500 processed.\n",
            "Frame 453/500 processed.\n",
            "Frame 454/500 processed.\n",
            "Frame 455/500 processed.\n",
            "Frame 456/500 processed.\n",
            "Frame 457/500 processed.\n",
            "Frame 458/500 processed.\n",
            "Frame 459/500 processed.\n",
            "Frame 460/500 processed.\n",
            "Frame 461/500 processed.\n",
            "Frame 462/500 processed.\n",
            "Frame 463/500 processed.\n",
            "Frame 464/500 processed.\n",
            "Frame 465/500 processed.\n",
            "Frame 466/500 processed.\n",
            "Frame 467/500 processed.\n",
            "Frame 468/500 processed.\n",
            "Frame 469/500 processed.\n",
            "Frame 470/500 processed.\n",
            "Frame 471/500 processed.\n",
            "Frame 472/500 processed.\n",
            "Frame 473/500 processed.\n",
            "Frame 474/500 processed.\n",
            "Frame 475/500 processed.\n",
            "Frame 476/500 processed.\n",
            "Frame 477/500 processed.\n",
            "Frame 478/500 processed.\n",
            "Frame 479/500 processed.\n",
            "Frame 480/500 processed.\n",
            "Frame 481/500 processed.\n",
            "Frame 482/500 processed.\n",
            "Frame 483/500 processed.\n",
            "Frame 484/500 processed.\n",
            "Frame 485/500 processed.\n",
            "Frame 486/500 processed.\n",
            "Frame 487/500 processed.\n",
            "Frame 488/500 processed.\n",
            "Frame 489/500 processed.\n",
            "Frame 490/500 processed.\n",
            "Frame 491/500 processed.\n",
            "Frame 492/500 processed.\n",
            "Frame 493/500 processed.\n",
            "Frame 494/500 processed.\n",
            "Frame 495/500 processed.\n",
            "Frame 496/500 processed.\n",
            "Frame 497/500 processed.\n",
            "Frame 498/500 processed.\n",
            "Frame 499/500 processed.\n",
            "Frame 500/500 processed.\n",
            "Processing completed!\n"
          ]
        }
      ],
      "source": [
        "def initialize_tracker() -> DeepSort:\n",
        "    \"\"\"Initialize the DeepSORT tracker.\"\"\"\n",
        "    return DeepSort(max_age=5, n_init=1, nms_max_overlap=0.2)\n",
        "\n",
        "def load_yolo_model(model_path: str) -> YOLO:\n",
        "    \"\"\"Load the YOLOv8 model.\"\"\"\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    return YOLO(model_path).to(device)\n",
        "\n",
        "def initialize_video_capture(video_path: str) -> cv2.VideoCapture:\n",
        "    \"\"\"Initialize video capture and verify it is opened successfully.\"\"\"\n",
        "    video_capture = cv2.VideoCapture(video_path)\n",
        "    if not video_capture.isOpened():\n",
        "        raise RuntimeError(\"Error: Could not open video file. Check if the file exists and is in a supported format.\")\n",
        "    return video_capture\n",
        "\n",
        "def initialize_video_writer(output_video_path: str, fps: int, frame_size: Tuple[int, int]) -> cv2.VideoWriter:\n",
        "    \"\"\"Initialize video writer and verify it is opened successfully.\"\"\"\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    video_writer = cv2.VideoWriter(output_video_path, fourcc, fps, frame_size)\n",
        "    if not video_writer.isOpened():\n",
        "        raise RuntimeError(\"Error: Could not open video writer.\")\n",
        "    return video_writer\n",
        "\n",
        "def process_frame(frame, yolo_model, tracker, class_colors: Dict[str, Tuple[int, int, int]], results_file: str, frame_idx: int) -> None:\n",
        "    \"\"\"Process a single frame: detect objects, update tracker, and write results.\"\"\"\n",
        "    results = yolo_model(frame, device='cuda' if torch.cuda.is_available() else 'cpu', verbose=False)[0]\n",
        "\n",
        "    processed_boxes = []\n",
        "    if results.boxes is not None:\n",
        "        boxes = results.boxes.xyxy.cpu().numpy()\n",
        "        confidences = results.boxes.conf.cpu().numpy()\n",
        "\n",
        "        for i, box in enumerate(boxes):\n",
        "            if confidences[i] < MIN_CONFIDENCE:\n",
        "                continue\n",
        "            xmin, ymin, xmax, ymax = map(int, box)\n",
        "            width, height = xmax - xmin, ymax - ymin\n",
        "            processed_boxes.append([[xmin, ymin, width, height], confidences[i]])\n",
        "\n",
        "    tracks = tracker.update_tracks(processed_boxes, frame=frame)\n",
        "\n",
        "    with open(results_file, \"a\") as f:\n",
        "        for track in tracks:\n",
        "            if not track.is_confirmed():\n",
        "                continue\n",
        "            track_id = track.track_id\n",
        "            class_name = track.det_class\n",
        "            color = class_colors.get(class_name, (255, 255, 255))\n",
        "\n",
        "            frame_num = frame_idx + 1\n",
        "            x1, y1, x2, y2 = track.to_ltrb()\n",
        "            conf = str(track.det_conf)[:4]\n",
        "\n",
        "            line = f\"{frame_num},{track_id},{x1},{y1},{x2 - x1},{y2 - y1},{conf},-1,-1,-1\\n\"\n",
        "            f.write(line)\n",
        "\n",
        "            x1, y1, w, h = map(int, track.to_ltwh())\n",
        "            x2, y2 = x1 + w, y1 + h\n",
        "            label = f\"{track_id}. {class_name} ({conf})\"\n",
        "            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
        "            cv2.putText(frame, label, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
        "\n",
        "MODEL_PATH = \"/content/models/best.pt\"\n",
        "VIDEO_PATH = \"/content/v_G-vNjfx1GGc_c600_video.mp4\"\n",
        "OUTPUT_VIDEO_PATH = \"/content/DeepSort_output.mp4\"\n",
        "RESULTS_DIR = \"/content/drive/My Drive/SportsMOT/test/results\"\n",
        "\n",
        "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
        "\n",
        "if not os.path.exists(VIDEO_PATH):\n",
        "    raise FileNotFoundError(f\"Error: The file {VIDEO_PATH} does not exist.\")\n",
        "\n",
        "CLASS_NAMES = [\"player\", \"referee\", \"ball\"]\n",
        "CLASS_COLORS = {\n",
        "    \"player\": (255, 255, 0),\n",
        "    \"referee\": (0, 0, 255),\n",
        "    \"ball\": (255, 0, 255)\n",
        "}\n",
        "\n",
        "MIN_CONFIDENCE = 0.5\n",
        "FRAME_SIZE = (1280, 720)\n",
        "FPS = 25\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main function to process the video and track objects.\"\"\"\n",
        "    tracker = initialize_tracker()\n",
        "    yolo_model = load_yolo_model(MODEL_PATH)\n",
        "\n",
        "    video_capture = initialize_video_capture(VIDEO_PATH)\n",
        "    video_writer = initialize_video_writer(OUTPUT_VIDEO_PATH, FPS, FRAME_SIZE)\n",
        "\n",
        "    total_frames = int(video_capture.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    frame_width = int(video_capture.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    frame_height = int(video_capture.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    fps = video_capture.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "    print(f\"Total frames: {total_frames}\")\n",
        "    print(f\"Frame size: {frame_width}x{frame_height}\")\n",
        "    print(f\"FPS: {fps}\")\n",
        "\n",
        "    frame_idx = 0\n",
        "    while True:\n",
        "        ret, frame = video_capture.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        frame = cv2.resize(frame, FRAME_SIZE)\n",
        "\n",
        "        process_frame(frame, yolo_model, tracker, CLASS_COLORS, os.path.join(RESULTS_DIR, \"tracking_results_deepsort.txt\"), frame_idx)\n",
        "\n",
        "        video_writer.write(frame)\n",
        "\n",
        "        print(f\"Frame {frame_idx + 1}/{total_frames} processed.\")\n",
        "\n",
        "        frame_idx += 1\n",
        "\n",
        "    video_capture.release()\n",
        "    video_writer.release()\n",
        "    print(\"Processing completed!\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "g7qJSPTD0C-D",
        "outputId": "3cef39c5-7834-49ff-c112-c11259145b23"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_81460bdc-c13c-409a-9803-f14a9767789d\", \"DeepSort_output.mp4\", 25587804)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download(\"/content/DeepSort_output.mp4\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yL8wTmdq6KFT"
      },
      "outputs": [],
      "source": [
        "gt_path = \"/root/.cache/kagglehub/datasets/ayushspai/sportsmot/versions/1/sportsmot_publish/dataset/val/v_G-vNjfx1GGc_c600/gt/gt.txt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import motmetrics as mm\n",
        "import pandas as pd\n",
        "from tabulate import tabulate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "w4rdJPkqTYdL"
      },
      "outputs": [],
      "source": [
        "def compute_mot_metrics(gt_file: str, ts_file: str, seqmap_file: str = None) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Compute MOT metrics (MOTA, precision, recall, IDF1, etc.) for tracking results.\n",
        "\n",
        "    Args:\n",
        "        gt_file (str): Path to the ground truth file.\n",
        "        ts_file (str): Path to the tracking results file.\n",
        "        seqmap_file (str, optional): Path to the sequence mapping file (if required).\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: A DataFrame containing the computed metrics.\n",
        "    \"\"\"\n",
        "    gt = mm.io.load_motchallenge(gt_file)\n",
        "    ts = mm.io.load_motchallenge(ts_file)\n",
        "\n",
        "    acc = mm.utils.compare_to_groundtruth(gt, ts, 'iou', distth=0.5)\n",
        "    mh = mm.metrics.create()\n",
        "\n",
        "    metrics = [\n",
        "        'mota', 'precision', 'idf1',\n",
        "        'num_false_positives',  \n",
        "        'num_switches',     \n",
        "        'num_fragmentations',    \n",
        "        'mostly_tracked',          \n",
        "        'partially_tracked',\n",
        "        'mostly_lost'      \n",
        "    ]\n",
        "\n",
        "    summary = mh.compute(acc, metrics=metrics, name='acc')\n",
        "\n",
        "    summary_df = pd.DataFrame(summary).transpose()\n",
        "\n",
        "    return summary_df\n",
        "\n",
        "def print_metrics_table(summary_df: pd.DataFrame) -> None:\n",
        "    \"\"\"\n",
        "    Print the MOT metrics in a table format.\n",
        "\n",
        "    Args:\n",
        "        summary_df (pd.DataFrame): DataFrame containing the computed metrics.\n",
        "    \"\"\"\n",
        "    table_data = summary_df.reset_index().values.tolist()\n",
        "    headers = [\"Metric\", \"Value\"]\n",
        "\n",
        "    print(tabulate(table_data, headers=headers, tablefmt=\"pretty\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_mro0azTbcp",
        "outputId": "27fc84c5-b73b-41a5-905e-a19f7ba910ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------------------+--------------------+\n",
            "|       Metric        |       Value        |\n",
            "+---------------------+--------------------+\n",
            "|        mota         | 0.7755400952032223 |\n",
            "|      precision      | 0.9330645161290323 |\n",
            "|        idf1         | 0.4958741124544233 |\n",
            "| num_false_positives |       332.0        |\n",
            "|    num_switches     |        60.0        |\n",
            "| num_fragmentations  |       163.0        |\n",
            "|   mostly_tracked    |        15.0        |\n",
            "|  partially_tracked  |        4.0         |\n",
            "|     mostly_lost     |        0.0         |\n",
            "+---------------------+--------------------+\n"
          ]
        }
      ],
      "source": [
        "gt_path = \"/content/drive/My Drive/SportsMOT/gt_cleaned.txt\"\n",
        "results_path = \"/content/drive/My Drive/SportsMOT/test/results/tracking_results_cleaned.txt\"\n",
        "\n",
        "metrics_summary = compute_mot_metrics(gt_path, results_path)\n",
        "\n",
        "print_metrics_table(metrics_summary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "F4M-ejfMIs_2"
      },
      "outputs": [],
      "source": [
        "def preprocess_file(input_file, output_file, num_fields):\n",
        "    \"\"\"\n",
        "    Preprocess a file to ensure it has the correct number of fields.\n",
        "\n",
        "    Args:\n",
        "        input_file (str): Path to the input file.\n",
        "        output_file (str): Path to the output file.\n",
        "        num_fields (int): Expected number of fields per line.\n",
        "    \"\"\"\n",
        "    with open(input_file, 'r') as infile, open(output_file, 'w') as outfile:\n",
        "        for line in infile:\n",
        "            fields = line.strip().split(',')\n",
        "            if len(fields) == num_fields:\n",
        "                outfile.write(line)\n",
        "            else:\n",
        "                print(f\"Skipping malformed line: {line.strip()}\")\n",
        "\n",
        "gt_input = \"/root/.cache/kagglehub/datasets/ayushspai/sportsmot/versions/1/sportsmot_publish/dataset/val/v_G-vNjfx1GGc_c600/gt/gt.txt\"\n",
        "gt_output = \"/content/drive/My Drive/SportsMOT/gt_processed.txt\"\n",
        "preprocess_file(gt_input, gt_output, num_fields=9)\n",
        "\n",
        "results_input = \"/content/drive/My Drive/SportsMOT/test/results/tracking_results_deepsort.txt\"\n",
        "results_output = \"/content/drive/My Drive/SportsMOT/test/results/tracking_results_processed.txt\"\n",
        "preprocess_file(results_input, results_output, num_fields=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "K0NCerSu7jZ_"
      },
      "outputs": [],
      "source": [
        "def clean_file(input_file, output_file, num_fields):\n",
        "    \"\"\"\n",
        "    Clean a file to ensure it has the correct number of fields and no extra spaces or quotes.\n",
        "\n",
        "    Args:\n",
        "        input_file (str): Path to the input file.\n",
        "        output_file (str): Path to the output file.\n",
        "        num_fields (int): Expected number of fields per line.\n",
        "    \"\"\"\n",
        "    with open(input_file, 'r') as infile, open(output_file, 'w') as outfile:\n",
        "        for line in infile:\n",
        "            line = line.strip().replace('\"', '').replace(\"'\", '')\n",
        "            line = ','.join([field.strip() for field in line.split(',')])\n",
        "            fields = line.split(',')\n",
        "            if len(fields) == num_fields:\n",
        "                outfile.write(','.join(fields) + '\\n')\n",
        "            else:\n",
        "                print(f\"Skipping malformed line: {line}\")\n",
        "\n",
        "gt_input = \"/content/drive/My Drive/SportsMOT/gt_processed.txt\"\n",
        "gt_output = \"/content/drive/My Drive/SportsMOT/gt_cleaned.txt\"\n",
        "clean_file(gt_input, gt_output, num_fields=9)\n",
        "\n",
        "results_input = \"/content/drive/My Drive/SportsMOT/test/results/tracking_results_processed.txt\"\n",
        "results_output = \"/content/drive/My Drive/SportsMOT/test/results/tracking_results_cleaned.txt\"\n",
        "clean_file(results_input, results_output, num_fields=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xsL-dWylxwz_",
        "outputId": "290ff105-d7eb-482e-82af-cc151ccd087d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                         acc\n",
            "mota                0.775540\n",
            "precision           0.933065\n",
            "recall              0.847309\n",
            "motp                0.190865\n",
            "idf1                0.495874\n",
            "idp                 0.520968\n",
            "idr                 0.473087\n",
            "num_switches       60.000000\n",
            "mostly_tracked     15.000000\n",
            "partially_tracked   4.000000\n",
            "mostly_lost         0.000000\n"
          ]
        }
      ],
      "source": [
        "gt_path = \"/content/drive/My Drive/SportsMOT/gt_cleaned.txt\"\n",
        "results_path = \"/content/drive/My Drive/SportsMOT/test/results/tracking_results_cleaned.txt\"\n",
        "metrics_summary = compute_mot_metrics(gt_path, results_path)\n",
        "print(metrics_summary)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
